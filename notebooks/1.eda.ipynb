{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u don\\'t have to be scared of the loud dog, I\\'ll protect you\". The mole felt so safe with the little girl. She was very kind and the mole soon came to trust her. He leaned against her and she kept him safe. The mole had found his best friend.\\n<|endoftext|>\\nOnce upon a time, in a warm and sunny place, there was a big pit. A little boy named Tom liked to play near the pit. One day, Tom lost his red ball. He was very sad.\\nTom asked his friend, Sam, to help him search for the ball. They looked high a'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../input/tinystories/TinyStoriesV2-GPT4-valid.txt\") as f:\n",
    "    valid = f.read()\n",
    "valid[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u',\n",
       " \"don't\",\n",
       " 'have',\n",
       " 'to',\n",
       " 'be',\n",
       " 'scared',\n",
       " 'of',\n",
       " 'the',\n",
       " 'loud',\n",
       " 'dog',\n",
       " '',\n",
       " \"I'll\",\n",
       " 'protect',\n",
       " 'you\".',\n",
       " 'The',\n",
       " 'mole',\n",
       " 'felt',\n",
       " 'so',\n",
       " 'safe',\n",
       " 'with',\n",
       " 'the',\n",
       " 'little',\n",
       " '']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valid[:500].split(\" \")\n",
    "re.split('\\n|,|\\s',valid[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22493387"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../input/tinystories/TinyStoriesV2-GPT4-valid.txt\") as f:\n",
    "    valid = f.read()\n",
    "# with open(\"../../input/tinystories/TinyStoriesV2-GPT4-train.txt\") as f:\n",
    "#     train = f.read()\n",
    "# train[:10]    \n",
    "alltext = valid\n",
    "len(alltext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {i[1]:i[0] for i in {'color': 'blue', 'fruit': 'apple', 'pet': 'dog'}.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all tokens: 10724573\n",
      "unique tokens : 9772\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    tokens = re.split('(\\n|,|\\s|\\.|\"|!|\\?|-|“|\\'|:|’|”|;|‘)',text)\n",
    "    return tokens\n",
    "alltokens = tokenize(alltext)\n",
    "print(\"all tokens: {}\".format(len(alltokens)))\n",
    "uniq_tokens = list(set(alltokens))\n",
    "print(\"unique tokens : {}\".format(len(uniq_tokens)))\n",
    "id_to_token_mapping = {id:token for id,token in enumerate(uniq_tokens)}\n",
    "token_to_id_mapping = {item[1]:item[0] for item in id_to_token_mapping.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9772,)\n",
      "(2185,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hamsters       2\n",
       "filter         2\n",
       "restoration    2\n",
       "911            2\n",
       "jiggle         2\n",
       "tow            2\n",
       "pounce         2\n",
       "hovered        2\n",
       "twirls         2\n",
       "rattling       2\n",
       "rubble         2\n",
       "insistent      2\n",
       "sucked         2\n",
       "vast           2\n",
       "warrior        2\n",
       "blurry         2\n",
       "prodded        2\n",
       "soothe         2\n",
       "bullets        2\n",
       "smoothness     2\n",
       "tastier        2\n",
       "crooked        2\n",
       "sometime       2\n",
       "areas          2\n",
       "displays       2\n",
       "              2\n",
       "majesty        2\n",
       "saucer         2\n",
       "adoringly      2\n",
       "ripping        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.Series(alltokens).value_counts()\n",
    "print(t.shape)\n",
    "print(t[t==1].shape)\n",
    "t[t>1].tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', ' ', 'don', \"'\", 't', ' ', 'have', ' ', 'to', ' ', 'be', ' ', 'scared', ' ', 'of', ' ', 'the', ' ', 'loud', ' ', 'dog', ',', '', ' ', 'i', \"'\", 'll', ' ', 'protect', ' ', 'you', '\"', '', '.', '', ' ', 'the', ' ', 'mole', ' ', 'felt', ' ', 'so', ' ', 'safe', ' ', 'with', ' ', 'the', ' ', 'little', ' ', 'girl', '.', '', ' ', 'she', ' ', 'was', ' ', 'very', ' ', 'kind', ' ', 'and', ' ', 'the', ' ', 'mole', ' ', 'soon', ' ', 'came', ' ', 'to', ' ', 'trust', ' ', 'her', '.', '', ' ', 'he', ' ', 'leaned', ' ', 'against', ' ', 'her', ' ', 'and', ' ', 'she', ' ', 'kept', ' ', 'him', ' ', 'safe', '.', '', ' ', 'the', ' ', 'mole', ' ', 'had', ' ', 'found', ' ', 'his', ' ', 'best', ' ', 'friend', '.', '', '\\n', '<|endoftext|>', '\\n', 'once', ' ', 'upon', ' ', 'a', ' ', 'time', ',', '', ' ', 'in', ' ', 'a', ' ', 'warm', ' ', 'and', ' ', 'sunny', ' ', 'place', ',', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'u don\\'t have to be scared of the loud dog, i\\'ll protect you\". the mole felt so safe with the little girl. she was very kind and the mole soon came to trust her. he leaned against her and she kept him safe. the mole had found his best friend.\\n<|endoftext|>\\nonce upon a time, in a warm and sunny place,'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenize(valid[:300]))\n",
    "\"\".join(tokenize(valid[:300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1431, 9031, 8430, 1673, 3910, 9031, 6629, 9031, 4230, 9031, 5558, 9031, 7566, 9031, 747, 9031, 9257, 9031, 2197, 9031, 6249, 6982, 0, 9031, 8597, 1673, 3504, 9031, 669, 9031, 6925, 8456, 0, 6598, 0, 9031, 9257, 9031, 7729, 9031, 3675, 9031, 3033, 9031, 9475, 9031, 5248, 9031, 9257, 9031, 4674, 9031, 4676, 6598, 0, 9031, 1940, 9031, 1676, 9031, 3575, 9031, 6031, 9031, 7744, 9031, 9257, 9031, 7729, 9031, 2936, 9031, 3558, 9031, 4230, 9031, 2160, 9031, 7170, 6598, 0, 9031, 3561, 9031, 7995, 9031, 8367, 9031, 7170, 9031, 7744, 9031, 1940, 9031, 6999, 9031, 6218, 9031, 9475, 6598, 0, 9031, 9257, 9031, 7729, 9031, 1794, 9031, 148, 9031, 4641, 9031, 9008, 9031, 7047, 6598, 0, 8988, 2436, 8988, 6897, 9031, 7219, 9031, 8247, 9031, 4247, 6982, 0, 9031, 4751, 9031, 8247, 9031, 2539, 9031, 7744, 9031, 2701, 9031, 6229, 6982, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'u don\\'t have to be scared of the loud dog, i\\'ll protect you\". the mole felt so safe with the little girl. she was very kind and the mole soon came to trust her. he leaned against her and she kept him safe. the mole had found his best friend.\\n<|endoftext|>\\nonce upon a time, in a warm and sunny place,'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_to_id(text):\n",
    "    tokens = tokenize(text)\n",
    "    ids = [token_to_id_mapping[t] for t in tokens]\n",
    "    return ids\n",
    "def detokenize_to_text(ids):\n",
    "    tokens = [id_to_token_mapping[t] for t in ids]\n",
    "    return \"\".join(tokens)\n",
    "print(tokenize_to_id(valid[:300]))\n",
    "detokenize_to_text(tokenize_to_id(valid[:300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "os.makedirs(\"output/config\",exist_ok=True)\n",
    "# .dumps() as a string\n",
    "json_string = json.dumps(token_to_id_mapping)\n",
    "with open('output/config/token_to_id_mapping.json', 'w') as outfile:\n",
    "    json.dump(json_string, outfile)\n",
    "json_string = json.dumps(id_to_token_mapping)\n",
    "with open('output/config/id_to_token_mapping.json', 'w') as outfile:\n",
    "    json.dump(json_string, outfile)    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
